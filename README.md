# ğŸ¤ TranscripciÃ³n de Audio con DiarizaciÃ³n# TranscripciÃ³n de Audio# ğŸ¤ TranscripciÃ³n de Audio con DiarizaciÃ³n



Sistema de transcripciÃ³n de audio y video con identificaciÃ³n automÃ¡tica de hablantes.



## âœ¨ CaracterÃ­sticasSistema de transcripciÃ³n de audio y video con identificaciÃ³n de hablantes.Sistema de transcripciÃ³n de audio y video con identificaciÃ³n automÃ¡tica de hablantes usando **Whisper** y **pyannote.audio**.



- âœ… TranscripciÃ³n precisa con OpenAI Whisper (modelo large-v2)

- âœ… IdentificaciÃ³n de hablantes con pyannote.audio

- âœ… **NumeraciÃ³n de hablantes desde SPEAKER_01** (mejorado)## CaracterÃ­sticas---

- âœ… ConversiÃ³n de video a audio (MP3)

- âœ… Procesamiento de videos largos por segmentos

- âœ… API REST con FastAPI

- âœ… Interfaz web amigable- TranscripciÃ³n de audio usando OpenAI Whisper (modelo large-v2)## âœ¨ CaracterÃ­sticas



## ğŸš€ Inicio RÃ¡pido

Este repositorio estÃ¡ preparado para deploy en DigitalOcean (DOCR + App Platform). A continuaciÃ³n las instrucciones rÃ¡pidas para CI y despliegue.

### CI / Deploy (DOCR)

Usamos un workflow de GitHub Actions (`.github/workflows/ci-docr.yml`) que construye y empuja imÃ¡genes a DO Container Registry (DOCR). Por defecto construye una imagen "minimal" usando `config/requirements.txt`. Opcionalmente puede construir una imagen "full" con dependencias pesadas si configuras el secreto `DO_FULL_IMAGE=true`.

Secrets necesarios en GitHub:
- `DIGITALOCEAN_ACCESS_TOKEN` â€” token con permisos para DOCR y App Platform.
- `DOCR_REGISTRY` â€” nombre de tu registry en DOCR (ej: my-registry).
- `DOCR_REPOSITORY` â€” nombre del repo de imagen en DOCR (ej: transcripcion-audio).
- (Opcional) `DO_FULL_IMAGE=true` â€” si quieres tambiÃ©n construir la imagen con `requirements-optional.txt`.
- (Opcional) `DO_APP_ID` â€” ID de la App Platform si quieres que el workflow actualice la app automÃ¡ticamente.

El workflow etiqueta la imagen con el SHA y con `latest`. Para usar la imagen en App Platform, edita `do_app_spec.yaml` con la ruta correcta del registry/repositorio.

### Dependencias: minimal vs full

Instala solo lo mÃ­nimo en producciÃ³n para reducir el tamaÃ±o de la imagen:

Minimal (recomendado para App Platform):
```
pip install -r config/requirements.txt
```

Full (GPU / mÃ¡quinas con suficiente RAM):
```
pip install -r config/requirements-optional.txt
```

ContinÃºa con el README existente...



```powershell- ConversiÃ³n de video a audio- âœ… TranscripciÃ³n de audio con Whisper (OpenAI)

# 1. Activar entorno virtual

.\venv\Scripts\Activate.ps1- Procesamiento de videos largos por segmentos- âœ… IdentificaciÃ³n de hablantes (diarizaciÃ³n)



# 2. Configurar token de Hugging Face en config/.env- API REST con FastAPI- âœ… ConversiÃ³n de videos a audio (MP3)

# HF_TOKEN=tu_token_aqui

- Interfaz web incluida- âœ… Soporte para videos largos (procesamiento por chunks)

# 3. Iniciar servidor

python main.py- âœ… API REST con FastAPI

```

## InstalaciÃ³n- âœ… Interfaz web amigable

Abre **http://127.0.0.1:8888** en tu navegador.

- âœ… MÃºltiples idiomas soportados

## ğŸ“¦ InstalaciÃ³n Completa

```powershell- âœ… ConfiguraciÃ³n flexible de modelos

```powershell

# Crear entorno virtualpython -m venv venv

python -m venv venv

.\venv\Scripts\Activate.ps1.\venv\Scripts\Activate.ps1---



# Instalar dependenciaspip install -r config\requirements.txt

pip install -r config\requirements.txt

```## ğŸš€ Inicio RÃ¡pido

# Configurar .env

Copy-Item "config\.env.example" "config\.env"

notepad "config\.env"  # Editar y agregar HF_TOKEN

```## ConfiguraciÃ³n### 1. **Configurar el proyecto**



## ğŸ¯ ConfiguraciÃ³n```powershell



Edita `config/.env`:Copia `config/.env.example` a `config/.env` y configura:# Ejecutar script de configuraciÃ³n automÃ¡tica



```env.\setup.ps1

# Token de Hugging Face (OBLIGATORIO para diarizaciÃ³n)

HF_TOKEN=tu_token_de_huggingface```env```



# Modelo de WhisperWHISPER_MODEL=large-v2

WHISPER_MODEL=large-v2

HF_TOKEN=tu_token_de_huggingface### 2. **Configurar HF_TOKEN**

# LÃ­mites

MAX_FILE_SIZE=524288000  # 500MBMAX_FILE_SIZE=524288000Edita `config/.env` y agrega tu token de Hugging Face:

```

``````env

**ObtÃ©n tu token:** https://huggingface.co/settings/tokens  

**Acepta tÃ©rminos:** https://huggingface.co/pyannote/speaker-diarization-3.1HF_TOKEN=hf_tu_token_aquÃ­



## ğŸ“¡ API Endpoints## Uso```



- `POST /transcribe` - Transcribir audio sin identificar hablantes

- `POST /transcribe-diarize` - Transcribir con identificaciÃ³n de hablantes

- `POST /convert-video` - Convertir video a audio MP3```powershell> **ObtÃ©n tu token:** https://huggingface.co/settings/tokens  

- `POST /convert-and-transcribe` - Convertir y transcribir en un paso

python main.py> **Acepta tÃ©rminos:** https://huggingface.co/pyannote/speaker-diarization-3.1

**DocumentaciÃ³n completa:** http://127.0.0.1:8888/docs

```

## ğŸ“ Ejemplo de Salida

### 3. **Iniciar servidor**

```

[SPEAKER_01]: Â¿CÃ³mo estarÃ¡n en la encenada? al viejo ceibal, Abre http://127.0.0.1:8888 en tu navegador.```powershell

los jazmineros y orquÃ­deas en flor...

python main.py

[SPEAKER_02]: Amor, no llores, veo luz en tus males, 

siguiÃ©ndote al corazÃ³n, bailando en un canto de solsales.## API Endpoints```



[SPEAKER_01]: NiÃ±o, soy un hombre con tristeza, sÃ© del peso 

en tu verdad, de escaparte por robar porque robas para cenar.

```- `POST /transcribe` - Transcribir audioEl servidor estarÃ¡ en: http://127.0.0.1:8888



## ğŸ’¡ Mejora Reciente- `POST /transcribe-diarize` - Transcribir con identificaciÃ³n de hablantes



Los hablantes ahora se numeran desde **SPEAKER_01** (en lugar de SPEAKER_00), haciendo la lectura mÃ¡s natural e intuitiva.- `POST /convert-video` - Convertir video a audio---



Ver detalles completos en: **MEJORA_SPEAKERS.md**- `POST /convert-and-transcribe` - Convertir y transcribir en un solo paso



## ğŸ”§ Requisitos del Sistema## ğŸ“¦ InstalaciÃ³n Manual



- **Python:** 3.13+## Requisitos

- **FFmpeg:** Instalado y en PATH

- **RAM:** 8GB recomendado```powershell

- **Espacio:** ~5GB para modelos

- **Internet:** Para descarga inicial de modelos- Python 3.13+# Crear entorno virtual



## ğŸ“ Estructura del Proyecto- FFmpeg (para conversiÃ³n de video)python -m venv venv



```- Token de Hugging Face (para diarizaciÃ³n).\venv\Scripts\Activate.ps1

â”œâ”€â”€ main.py                    # Servidor FastAPI

â”œâ”€â”€ config/

â”‚   â”œâ”€â”€ .env                   # ConfiguraciÃ³n# Instalar dependencias

â”‚   â””â”€â”€ requirements.txt       # Dependenciaspip install -r config/requirements.txt

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ transcriber.py         # Whisper# Configurar .env

â”‚   â”œâ”€â”€ diarizer.py            # pyannoteCopy-Item "config\.env.example" "config\.env"

â”‚   â”œâ”€â”€ video_converter.py     # FFmpegnotepad "config\.env"  # Agregar HF_TOKEN

â”‚   â””â”€â”€ utils.py               # Utilidades

â””â”€â”€ web/                       # Interfaz web# Iniciar

```python main.py

```

## ğŸ› SoluciÃ³n de Problemas

---

**Error: HF_TOKEN no configurado**

```powershell## ğŸ¯ Modelos de Whisper

notepad config\.env  # Agregar HF_TOKEN

```Cambia el modelo en `config/.env`:



**FFmpeg no encontrado**| Modelo | PrecisiÃ³n | Velocidad | Recomendado Para |

```powershell|--------|-----------|-----------|------------------|

choco install ffmpeg  # Windows con Chocolatey| `tiny` | â­â­ | âš¡âš¡âš¡âš¡âš¡ | Pruebas rÃ¡pidas |

```| `base` | â­â­â­ | âš¡âš¡âš¡âš¡ | Uso general |

| `small` | â­â­â­â­ | âš¡âš¡âš¡ | **Balance ideal** |

**TranscripciÃ³n con errores**| `medium` | â­â­â­â­â­ | âš¡âš¡ | **EspaÃ±ol (recomendado)** |

- Usa modelo `medium` o `large-v2` para espaÃ±ol| `large-v2` | â­â­â­â­â­ | âš¡ | MÃ¡xima precisiÃ³n |

- AsegÃºrate de tener buena calidad de audio

```env

## ğŸ“š DocumentaciÃ³nWHISPER_MODEL=medium  # Para mejor precisiÃ³n en espaÃ±ol

```

- **MEJORA_SPEAKERS.md** - Detalles de numeraciÃ³n de hablantes

- **ESTADO.md** - Estado actual del proyectoğŸ“– **GuÃ­a completa:** Ver `MODELOS_WHISPER.md`

- **/docs** - DocumentaciÃ³n interactiva de la API

---

## ğŸ™ CrÃ©ditos

## ğŸ¬ Procesamiento de Videos Largos

- [OpenAI Whisper](https://github.com/openai/whisper)

- [pyannote.audio](https://github.com/pyannote/pyannote-audio)El sistema ahora divide automÃ¡ticamente videos largos en chunks para evitar timeouts:

- [FastAPI](https://fastapi.tiangolo.com/)

- [FFmpeg](https://ffmpeg.org/)- âœ… Videos >30 min se procesan automÃ¡ticamente por segmentos

- âœ… Timeout dinÃ¡mico basado en duraciÃ³n

---- âœ… ConcatenaciÃ³n automÃ¡tica de resultados

- âœ… Sin lÃ­mite de duraciÃ³n (solo lÃ­mite de tamaÃ±o de archivo)

**VersiÃ³n:** 2.0.0  

**Ãšltima actualizaciÃ³n:** 5 de octubre de 2025  Para ajustar el tamaÃ±o de chunks, edita `config/.env`:

**Estado:** âœ… Funcionando```env

VIDEO_CHUNK_DURATION=600  # segundos (10 minutos)
```

---

## ğŸ“¡ API Endpoints

### **1. Transcribir Audio**
```bash
POST /transcribe
```

### **2. Transcribir con DiarizaciÃ³n**
```bash
POST /transcribe-diarize
```

### **3. Convertir Video a Audio**
```bash
POST /convert-video
```

### **4. Convertir y Transcribir Video**
```bash
POST /convert-and-transcribe
```

ğŸ“š **DocumentaciÃ³n completa:** http://127.0.0.1:8888/docs

---

## ğŸ”§ ConfiguraciÃ³n

Archivo `config/.env`:

```env
# Token de Hugging Face (OBLIGATORIO)
HF_TOKEN=hf_tu_token

# Modelo de Whisper
WHISPER_MODEL=medium

# Servidor
HOST=127.0.0.1
PORT=8888

# LÃ­mites
MAX_FILE_SIZE=104857600  # 100MB
```

---

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ main.py              # Servidor FastAPI (RAÃZ)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .env             # ConfiguraciÃ³n
â”‚   â””â”€â”€ requirements.txt # Dependencias
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ transcriber.py   # MÃ³dulo Whisper
â”‚   â”œâ”€â”€ diarizer.py      # MÃ³dulo pyannote
â”‚   â”œâ”€â”€ video_converter.py  # ConversiÃ³n de videos
â”‚   â””â”€â”€ utils.py         # Utilidades
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html       # Interfaz web
â”‚   â”œâ”€â”€ styles.css
â”‚   â””â”€â”€ app.js
â”œâ”€â”€ uploads/             # Archivos temporales
â”œâ”€â”€ scripts/             # Scripts de utilidad
â”œâ”€â”€ setup.ps1            # ConfiguraciÃ³n automÃ¡tica
â”œâ”€â”€ restart.ps1          # Reiniciar servidor
â””â”€â”€ cleanup.ps1          # Limpiar archivos temporales
```

---

## ğŸ› SoluciÃ³n de Problemas

### **Error: HF_TOKEN no configurado**
```powershell
# Editar .env y agregar tu token
notepad config\.env
```

### **Error: FFmpeg no encontrado**
```powershell
# Instalar FFmpeg
choco install ffmpeg
```

### **Video muy largo no se procesa**
El sistema ahora procesa automÃ¡ticamente videos largos. Si aÃºn falla:
1. Verifica espacio en disco
2. Aumenta `MAX_FILE_SIZE` en `.env`
3. Usa modelo mÃ¡s pequeÃ±o: `WHISPER_MODEL=small`

### **TranscripciÃ³n con errores**
Usa un modelo mÃ¡s grande:
```env
WHISPER_MODEL=medium  # En lugar de base/tiny
```

ğŸ“– Lee `MODELOS_WHISPER.md` para mÃ¡s detalles

---

## ğŸ§¹ Mantenimiento

```powershell
# Limpiar archivos temporales
.\cleanup.ps1

# Reiniciar servidor limpiamente
.\restart.ps1

# Verificar configuraciÃ³n
python scripts/check_config.py
```

## ğŸ“„ Exportar a DOCX / PDF

Puedes pedir que la transcripciÃ³n se devuelva como archivo Word (.docx) o PDF (.pdf) directamente desde los endpoints de transcripciÃ³n.

- ParÃ¡metro (form): `download_format` â€” valores aceptados: `docx`, `pdf`.
- Si incluyes `background_tasks` en la peticiÃ³n (FastAPI BackgroundTasks), el archivo exportado se eliminarÃ¡ automÃ¡ticamente despuÃ©s de la respuesta.

Ejemplo (curl):

```bash
curl -X POST "http://127.0.0.1:8888/transcribe" \
	-F "file=@mi_audio.wav" \
	-F "download_format=docx" \
	-o resultado.docx
```

Requisitos adicionales: instala `python-docx` y `reportlab` para habilitar las exportaciones:

```powershell
pip install python-docx reportlab
```

---

## ğŸ“Š Requisitos del Sistema

- **Python:** 3.8+
- **RAM:** 4GB mÃ­nimo (8GB recomendado para `medium`)
- **Espacio:** 5GB (modelos + dependencias)
- **FFmpeg:** Instalado y en PATH
- **Internet:** Para primera descarga de modelos

---

## ğŸ“ Uso desde la Interfaz Web

1. Abre http://127.0.0.1:8888
2. Arrastra tu archivo de audio/video
3. Selecciona opciones (idioma, hablantes)
4. Click en "Transcribir"
5. Descarga el resultado

---

## ğŸ¤ ContribuciÃ³n

Este es un proyecto personal. Puedes:
- Reportar bugs
- Sugerir mejoras
- Hacer fork y personalizar

---

## ğŸ“ Licencia

Uso libre para proyectos personales y comerciales.

---

## ğŸ™ CrÃ©ditos

- [OpenAI Whisper](https://github.com/openai/whisper) - TranscripciÃ³n
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) - DiarizaciÃ³n
- [FastAPI](https://fastapi.tiangolo.com/) - Framework web
- [FFmpeg](https://ffmpeg.org/) - Procesamiento de video

---

## ğŸ“ Soporte

- **DocumentaciÃ³n de modelos:** `MODELOS_WHISPER.md`
- **API Docs:** http://127.0.0.1:8888/docs
- **Verificar config:** `python scripts/check_config.py`

---

**VersiÃ³n:** 2.0.0  
**Ãšltima actualizaciÃ³n:** 5 de octubre de 2025  
**Estado:** âœ… Funcionando
